# -*- coding: utf-8 -*-
"""scrapping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VJCY1Q2mA29iwEXVF9HB0hY6kk_KLISW
"""

pip install requests pandas scikit-learn

import requests
import base64
import pandas as pd
import time
import re

GITHUB_TOKEN = "ghp_token"     # <--- Add token here
headers = {"Authorization": f"token {GITHUB_TOKEN}"}

# ------------------------------------------------------
# Remove all Java comments
# ------------------------------------------------------
def remove_java_comments(code):
    # Remove /* */ multi-line and /** */ Javadoc
    code = re.sub(r"/\*[\s\S]*?\*/", "", code)
    # Remove // single-line comments
    code = re.sub(r"//.*", "", code)
    return code.strip()


# ------------------------------------------------------
# Fetch top Java repos
# ------------------------------------------------------
def get_top_java_repos(n=10):
    url = "https://api.github.com/search/repositories"
    params = {
        "q": "language:Java",
        "sort": "stars",
        "order": "desc",
        "per_page": n
    }
    r = requests.get(url, headers=headers, params=params)
    return r.json()["items"]


# ------------------------------------------------------
# Retrieve list of .java files from repo
# ------------------------------------------------------
def get_java_files(repo_full_name):
    url = f"https://api.github.com/repos/{repo_full_name}/git/trees/master?recursive=1"
    r = requests.get(url, headers=headers)
    if r.status_code != 200:
        return []
    data = r.json()
    return [f["path"] for f in data.get("tree", []) if f["path"].endswith(".java")]


# ------------------------------------------------------
# Fetch file content
# ------------------------------------------------------
def get_file_content(repo_full_name, file_path):
    url = f"https://api.github.com/repos/{repo_full_name}/contents/{file_path}"
    r = requests.get(url, headers=headers)
    if r.status_code != 200:
        return None
    content = r.json().get("content", "")
    try:
        return base64.b64decode(content).decode("utf-8", errors="ignore")
    except:
        return None


# ------------------------------------------------------
# Main
# ------------------------------------------------------
def main():
    repos = get_top_java_repos()
    dataset = []

    for repo in repos:
        fullname = repo["full_name"]
        print(f"[+] Processing repo: {fullname}")

        files = get_java_files(fullname)
        for fpath in files[:50]:     # Limit per repo (to control size)
            code = get_file_content(fullname, fpath)
            if code:
                clean_code = remove_java_comments(code)
                if clean_code.strip():   # Don't add empty code
                    dataset.append({
                        "repo": fullname,
                        "file": fpath,
                        "code": clean_code
                    })
            time.sleep(0.3)

    df = pd.DataFrame(dataset)
    df.to_csv("java_dataset.csv", index=False)
    print("[+] Saved cleaned dataset â†’ java_dataset.csv")


if __name__ == "__main__":
    main()

import pandas as pd
import random


df = pd.read_csv("java_dataset.csv")


# --------------------------------------
# 1. Make incomplete code for autocode
# --------------------------------------
def make_incomplete_code(code):
    lines = code.split("\n")
    if len(lines) < 4:
        return code   # cannot truncate small files
    cut = random.randint(1, len(lines) - 2)
    return "\n".join(lines[:cut])


# --------------------------------------
# 2. Introduce a simple bug
# --------------------------------------
def make_buggy_code(code):
    # Remove a random semicolon
    if ";" in code:
        return code.replace(";", "", 1)
    return code


# --------------------------------------
# 3. Generate test-case prompts
# --------------------------------------
def generate_testcase_prompt(code):
    return (
        "Generate high-level test cases for the following Java code. "
        "DO NOT return code. Only return test case descriptions.\n\n"
        + code
    )


# -----------------------------------------------------
# Build 3 datasets
# -----------------------------------------------------
completion_data = []
debugging_data = []
test_data = []

for _, row in df.iterrows():
    code = row["code"]

    # Auto code completion
    completion_data.append({
        "input": make_incomplete_code(code),
        "output": code
    })

    # Debugging
    debugging_data.append({
        "input": make_buggy_code(code),
        "output": code
    })

    # Test case generation
    test_data.append({
        "input": code,
        "output": generate_testcase_prompt(code)
    })


pd.DataFrame(completion_data).to_csv("autocode_completion.csv", index=False)
pd.DataFrame(debugging_data).to_csv("debugging.csv", index=False)
pd.DataFrame(test_data).to_csv("testcase_generation.csv", index=False)

print("[+] Generated datasets:")
print("    autocode_completion.csv")
print("    debugging.csv")
print("    testcase_generation.csv")

import pandas as pd
import time
from openai import OpenAI

# ------------------------------
# INIT CLIENT
# ------------------------------
client = OpenAI(api_key="sk-key")

# ------------------------------
# GENERATE TESTCASES USING NEW API
# ------------------------------
def generate_testcases(code):
    prompt = f"""
You are a test case generator.

### TASK ###
Read the Java code and generate meaningful testcases.
Compute real outputs according to the code logic.

### FORMAT (STRICT) ###
input : <values>
output : <value>

Leave a blank line between testcases.
Only output testcases.

### CODE ###
{code}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )
        return response.choices[0].message.content

    except Exception as e:
        print("LLM Error:", e)
        return ""


# ------------------------------
# READ SOURCE DATA
# ------------------------------
df = pd.read_csv("java_dataset.csv")

outputs = []

print("Generating testcases...\n")

for i, row in df.iterrows():
    code = row["code"]

    print(f"Processing snippet {i+1}/{len(df)}...")

    out = generate_testcases(code)

    if out.strip() == "":
        continue

    outputs.append({
        "input": code,
        "output": out
    })

    time.sleep(0.8)   # Reduce API rate-limit issues


# ------------------------------
# SAVE DATASET
# ------------------------------
pd.DataFrame(outputs).to_csv("testcase_generation.csv", index=False)

print("\nDONE! Saved testcase_generation.csv")